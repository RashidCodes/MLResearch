{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#INTRODUCTION\" data-toc-modified-id=\"INTRODUCTION-1\">INTRODUCTION</a></span></li><li><span><a href=\"#DATA-PREPROCESSING\" data-toc-modified-id=\"DATA-PREPROCESSING-2\">DATA PREPROCESSING</a></span><ul class=\"toc-item\"><li><span><a href=\"#List-of-features\" data-toc-modified-id=\"List-of-features-2.1\">List of features</a></span></li><li><span><a href=\"#Important-Features\" data-toc-modified-id=\"Important-Features-2.2\">Important Features</a></span></li><li><span><a href=\"#Dealing-with-Missing-Values\" data-toc-modified-id=\"Dealing-with-Missing-Values-2.3\">Dealing with Missing Values</a></span></li><li><span><a href=\"#Handling-Categorical-Data\" data-toc-modified-id=\"Handling-Categorical-Data-2.4\">Handling Categorical Data</a></span></li><li><span><a href=\"#Visualization\" data-toc-modified-id=\"Visualization-2.5\">Visualization</a></span></li><li><span><a href=\"#THE-NAIVE-WAY\" data-toc-modified-id=\"THE-NAIVE-WAY-2.6\">THE NAIVE WAY</a></span></li><li><span><a href=\"#Splitting-our-data-into-training-and-test-sets.\" data-toc-modified-id=\"Splitting-our-data-into-training-and-test-sets.-2.7\">Splitting our data into training and test sets.</a></span></li><li><span><a href=\"#Standardization\" data-toc-modified-id=\"Standardization-2.8\">Standardization</a></span></li></ul></li><li><span><a href=\"#TRAINING\" data-toc-modified-id=\"TRAINING-3\">TRAINING</a></span></li><li><span><a href=\"#MODEL-EVALUATION\" data-toc-modified-id=\"MODEL-EVALUATION-4\">MODEL EVALUATION</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Learning-Curve\" data-toc-modified-id=\"The-Learning-Curve-4.1\">The Learning Curve</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deductions\" data-toc-modified-id=\"Deductions-4.1.1\">Deductions</a></span></li></ul></li><li><span><a href=\"#Validation-Curve\" data-toc-modified-id=\"Validation-Curve-4.2\">Validation Curve</a></span></li><li><span><a href=\"#The-Confusion-Matrix\" data-toc-modified-id=\"The-Confusion-Matrix-4.3\">The Confusion Matrix</a></span></li><li><span><a href=\"#The-Receiver-Operating-Characteristic\" data-toc-modified-id=\"The-Receiver-Operating-Characteristic-4.4\">The Receiver Operating Characteristic</a></span></li></ul></li><li><span><a href=\"#SUMMARY\" data-toc-modified-id=\"SUMMARY-5\">SUMMARY</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning is mostly used to make predictions from already existing data. I am very **new** to machine learning so in this notebook, my goal is to familiarize myself with already existing algorithms and how to apply to them. The classifier i'll be using here is the ***Logistic Regression classifier***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start by getting familiar with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING\n",
    "### List of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## let's import the data\n",
    "data = pd.read_csv('Churn_Modelling.csv')\n",
    "data.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Features\n",
    "I won't be using all the dimensions in my dataset for now so I dropped a few columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## these are the features I want to use for now.\n",
    "data.columns[3:-1]\n",
    "\n",
    "## let's drop the features I won't be using.\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Missing Values\n",
    "Luckily for me, I do not have any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical Data\n",
    "Some of the columns in the dataset contain categorical data, typically the Gender and Geography fields. Let's do something about those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Churn_Modelling.csv')\n",
    "\n",
    "## dropping a few features\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "## let's dummy up a few features\n",
    "geog_gend = pd.get_dummies(data[['Geography', 'Gender']], drop_first=True)\n",
    "\n",
    "## appending the dummied features to the main dataframe\n",
    "## first drop the original data\n",
    "data = data.drop(['Geography', 'Gender'], axis=1)\n",
    "\n",
    "## now append the dummied features\n",
    "data['Geography_Germany'] = geog_gend['Geography_Germany']\n",
    "data['Geography_Spain'] = geog_gend['Geography_Spain']\n",
    "data['Gender_Male'] = geog_gend['Gender_Male']\n",
    "\n",
    "data.to_csv('data_new.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "We can use ***seaborn*** to plot the relationships between the features as well as their individual distributions. I'll use this method because later in my research, I will talk about the relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "## I am more interested in the diagonals.\n",
    "data = pd.read_csv('data_new.csv')\n",
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To satisfy my curiosity, I'll plot the distribution of the Age Feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "ages = data['Age'].values\n",
    "plt.hist(ages, histtype='step', align='mid')\n",
    "plt.xlabel('Ages')\n",
    "plt.ylabel('Number of People')\n",
    "plt.title('Distribution of Ages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like most of the customers in this data are between the ages of **30 - 40**. Good stuff. However I also want to know if there is a relationship between a customer's ***age*** and his ***salary***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = data['Age'].values\n",
    "estimated_salary = data['EstimatedSalary'].values\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "plt.scatter(ages, estimated_salary)\n",
    "plt.grid()\n",
    "plt.xlabel('Ages')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.title('Estimated Salaries with Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to see that the number of people that work reduce with age, because there are less and less salaries recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE NAIVE WAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some **assumptions** that have to be made before using Logistic Regression on any dataset. Below I have listed some of the ones that I found while researching.\n",
    "- Logisitic regression does not require a linear relationship between the dependent and independent variable.\n",
    "- Homoscedasticity is not required unlike in linear regression.\n",
    "- The dependent variable is not measured on an interval.\n",
    "- Observations must be independent of each other, in other words, observations should not come from repeated   measurements or matched data.\n",
    "- Logistic regression assumes linearity of independent variables and log odds.\n",
    "- The dependent variable should be dichotomous in nature.\n",
    "- It works well when there are no outliers in your data.\n",
    "- It also works well when there is no multicollinearity in our predictors. \n",
    "- The dataset must be linearly seperable.\n",
    "\n",
    "***PS***. A logistic regression model would do better on a dataset that has a **balanced distribution** of classes, compared to a dataset that has an imbalance. There are a number of ways to go about class imbalance, and I will explore some of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But I'll start by training my model in a **Naive way**, I won't consider any of the assumptions listed above. Later I'll compare the performance of this model with one that follows the assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting our data into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I am sure my dataset only contains numeric values, I'll split them into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data_new.csv')\n",
    "data = np.array(data)\n",
    "X = data[:, :-1] \n",
    "y = data[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many learning algorithms require input features on the same scale for optimal performance. So we'll standardize our data using ***sklearn***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train our multivariate logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='lbfgs', random_state=123)\n",
    "\n",
    "## k-fold cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "folds = StratifiedKFold(n_splits=10, random_state=1).split(X_train_std, y_train)\n",
    "\n",
    "## now we'll train our model\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(folds):\n",
    "    lr.fit(X_train_std[train], y_train[train])\n",
    "    score = lr.score(X_train_std[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    print(\"Fold %2d, Class Distribution.: %s, Acc %.3f\" % (k+1, np.bincount(y_train[train].astype(int)), score))\n",
    "\n",
    "print('\\nCV Accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using my lazy way, I was able to achieve an accuracy of 57.2%. This is not good at all, hopefully i'll be able to make it in the next chapter of this research. ***'CustomerChurn2.ipynb'***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Techniques:\n",
    "    - ROC AUC\n",
    "    - Learning Curve\n",
    "    - Validation Curve\n",
    "    \n",
    "We'll also look at the **f1, precision and recall scores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Learning Curve\n",
    "We want to know whether adding more samples to our dataset will increase accuracy. The learning curve will also be able to tell us if our model overfit or underfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=lr, X=X_train_std, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10), cv=10, n_jobs=1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='magenta', marker='o', markersize=5, label='training accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='magenta')\n",
    "\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, color='green', alpha=0.15)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "# plt.ylim([0.7, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deductions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our model clearly underfits the data.\n",
    "- Adding more samples will not increase the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Curve\n",
    "Our model does not overfit our data, therefore regularization of the learned parameters will not do us any good. Let's visualize this by varying our regularization parameter C, in our LogisiticRegression instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0, 100000.0]\n",
    "train_scores, test_scores = validation_curve(estimator=lr, X=X_train_std, y=y_train, param_name='C', param_range=param_range, cv=10)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(param_range, train_mean, color='magenta', marker='o', markersize=5, label='training accuracy')\n",
    "\n",
    "plt.fill_between(param_range, train_mean + train_std, train_mean - train_std, alpha=0.15, color='magenta')\n",
    "\n",
    "plt.plot(param_range, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\n",
    "\n",
    "plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, color='green', alpha=0.15)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Parameter C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with low regularization strength(10**5), the performance of the model does improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Confusion Matrix\n",
    "The confusion matrix categorises our predictions into true positives, true negatives, false positives and false negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_predicted = lr.predict(X_test_std)\n",
    "confmat = confusion_matrix(y_true = y_test, y_pred = y_predicted)\n",
    "\n",
    "## and we have our confusion matrix, let's make it look a little bit prettier\n",
    "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Greens, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1307 misclassified samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Receiver Operating Characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "## let's create a list of our cross_validation splits\n",
    "cv = list(StratifiedKFold(n_splits=3, random_state=1).split(X_train_std, y_train))\n",
    "\n",
    "## let's create a new figure for our curve\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "## plot the ROC curves for each fold\n",
    "for i, (train, test) in enumerate(cv):\n",
    "    probas = lr.fit(X_train_std[train], y_train[train]).predict_proba(X_train_std[test])\n",
    "    fpr, tpr, thresholds = roc_curve(y_train[test], probas[:, 1], pos_label=1)\n",
    "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='ROC fold %d (area = %0.2f)' % (i+1, roc_auc))\n",
    "\n",
    "\n",
    "## Let's plot the curve for random guessing\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color=(0.5, 0.5, 0.5), label='random guessing')\n",
    "\n",
    "\n",
    "## grabbing the mean_tpr over k=3 splits\n",
    "mean_tpr = mean_tpr / len(cv)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='black', linestyle='--', label='mean ROC (area = %0.2f' % mean_auc, linewidth=2)\n",
    "\n",
    "## let's plot the curve for perfect performance\n",
    "plt.plot([0, 0, 1], [0, 1, 1], 'k:', label='perfect performance')\n",
    "\n",
    "# Some Annotation\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARY\n",
    "I used a ***Logistic regression model*** to predict customer churn with an accuracy of 57.2%, just a little over random guessing. I did ***fair*** data preprocessing and I did not follow most of the ***assumptions*** for using a ***Logistic regression model***. With 4 ***model evaluation techniques***, I was able to summarize the performance of my model. In my next research ***(CustomerChurn2.ipynb)***, I will consider all the assumptions I stated above regarding Logistic Regression. Hopefully, that model will be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Tree of Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
